Using device: cuda
GPU: NVIDIA GeForce GTX 1660 Ti
============================================================
Reproducing Figure 1: Training Loss vs Depth for Different Task Ranks
from 'The Low-Rank Simplicity Bias in Deep Networks'
============================================================

Configuration:
  Depths: [2, 4, 8, 16, 32, 48, 64]
  Ranks: [1, 4, 16, 32, 64]
  LR heuristic: 0.1 / sqrt(depth) * [0.1, 0.25, 0.5, 1.0, 2.0]
  Seeds: 1 task x 1 init = 1 runs per config
  Epochs: 4000
  Dimension: 64
  Samples: 128

Total training runs: 175

============================================================
Task Rank: 1
============================================================
  Depth  2: loss = 0.000048 +/- 0.000000, best_lr ~ 0.1414 (33.0s, ETA: 18.7min)
  Depth  4: loss = 0.000185 +/- 0.000000, best_lr ~ 0.0250 (26.7s, ETA: 16.4min)
  Depth  8: loss = 0.001332 +/- 0.000000, best_lr ~ 0.0035 (40.2s, ETA: 17.8min)
  Depth 16: loss = 0.000771 +/- 0.000000, best_lr ~ 0.0013 (51.8s, ETA: 19.6min)
  Depth 32: loss = 0.000593 +/- 0.000000, best_lr ~ 0.0004 (140.6s, ETA: 29.2min)
  Depth 48: loss = 0.000500 +/- 0.000000, best_lr ~ 0.0001 (190.2s, ETA: 38.9min)
  Depth 64: loss = 0.001220 +/- 0.000000, best_lr ~ 0.0001 (203.8s, ETA: 45.8min)

============================================================
Task Rank: 4
============================================================
  Depth  2: loss = 0.000017 +/- 0.000000, best_lr ~ 0.1414 (28.4s, ETA: 40.2min)
  Depth  4: loss = 0.000125 +/- 0.000000, best_lr ~ 0.0500 (32.7s, ETA: 36.0min)
  Depth  8: loss = 0.001151 +/- 0.000000, best_lr ~ 0.0177 (44.6s, ETA: 33.0min)
  Depth 16: loss = 0.003775 +/- 0.000000, best_lr ~ 0.0025 (79.8s, ETA: 31.7min)
  Depth 32: loss = 0.016099 +/- 0.000000, best_lr ~ 0.0004 (177.1s, ETA: 33.5min)
  Depth 48: loss = 0.059449 +/- 0.000000, best_lr ~ 0.0001 (218.9s, ETA: 35.8min)
  Depth 64: loss = 0.282520 +/- 0.000000, best_lr ~ 0.0001 (161.0s, ETA: 35.7min)

============================================================
Task Rank: 16
============================================================
  Depth  2: loss = 0.000001 +/- 0.000000, best_lr ~ 0.1414 (30.7s, ETA: 32.4min)
  Depth  4: loss = 0.000028 +/- 0.000000, best_lr ~ 0.0500 (36.5s, ETA: 29.6min)
  Depth  8: loss = 0.000115 +/- 0.000000, best_lr ~ 0.0177 (49.8s, ETA: 27.3min)
  Depth 16: loss = 0.000994 +/- 0.000000, best_lr ~ 0.0063 (102.4s, ETA: 25.9min)
  Depth 32: loss = 0.041350 +/- 0.000000, best_lr ~ 0.0009 (205.0s, ETA: 26.0min)
  Depth 48: loss = 2.610850 +/- 0.000000, best_lr ~ 0.0001 (225.7s, ETA: 26.0min)
  Depth 64: loss = 12.542616 +/- 0.000000, best_lr ~ 0.0001 (235.8s, ETA: 25.7min)

============================================================
Task Rank: 32
============================================================
  Depth  2: loss = 0.000003 +/- 0.000000, best_lr ~ 0.1414 (26.5s, ETA: 23.1min)
  Depth  4: loss = 0.000081 +/- 0.000000, best_lr ~ 0.0250 (35.3s, ETA: 20.7min)
  Depth  8: loss = 0.006770 +/- 0.000000, best_lr ~ 0.0035 (49.1s, ETA: 18.5min)
  Depth 16: loss = 0.041809 +/- 0.000000, best_lr ~ 0.0025 (112.4s, ETA: 16.9min)
  Depth 32: loss = 0.090316 +/- 0.000000, best_lr ~ 0.0018 (200.3s, ETA: 15.8min)
  Depth 48: loss = 7.517624 +/- 0.000000, best_lr ~ 0.0001 (209.1s, ETA: 14.6min)
  Depth 64: loss = 21.455034 +/- 0.000000, best_lr ~ 0.0003 (307.5s, ETA: 13.6min)

============================================================
Task Rank: 64
============================================================
  Depth  2: loss = 0.018118 +/- 0.000000, best_lr ~ 0.0707 (27.0s, ETA: 11.3min)
  Depth  4: loss = 0.151336 +/- 0.000000, best_lr ~ 0.0125 (36.6s, ETA: 9.2min)
  Depth  8: loss = 0.413218 +/- 0.000000, best_lr ~ 0.0035 (52.8s, ETA: 7.2min)
  Depth 16: loss = 0.668699 +/- 0.000000, best_lr ~ 0.0125 (126.9s, ETA: 5.5min)
  Depth 32: loss = 1.492797 +/- 0.000000, best_lr ~ 0.0009 (213.6s, ETA: 3.7min)
  Depth 48: loss = 12.735277 +/- 0.000000, best_lr ~ 0.0001 (262.3s, ETA: 1.9min)
  Depth 64: loss = 30.002804 +/- 0.000000, best_lr ~ 0.0001 (271.2s, ETA: 0.0min)

============================================================
Experiment completed in 70.8 minutes
============================================================

======================================================================
BEST LEARNING RATES SUMMARY
======================================================================
LR heuristic: lr = 0.1 / sqrt(depth) * multiplier
Multipliers tried: [0.1, 0.25, 0.5, 1.0, 2.0]
----------------------------------------------------------------------
Depth   Theory LR   Rank=1     Rank=4     Rank=16    Rank=32    Rank=64    
----------------------------------------------------------------------
2       0.0707      